# llama-4bit-128g-autogptq
## 使用autogptq量化的4bit llama1模型
  - 7 B：✅
  - 13B：✅
  - 30B：✅
  - 65B: ❌
